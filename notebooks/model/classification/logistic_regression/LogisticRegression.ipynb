{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_type\n",
       "positive    10728\n",
       "neutral     10728\n",
       "negative    10728\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"naive_bayes\\\\df_to_train.csv\")\n",
    "df['Total_Review'] = df['Total_Review'].fillna('')\n",
    "df.review_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_type\n",
       " 1    10728\n",
       " 0    10728\n",
       "-1    10728\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review_type = df['review_type'].map({'positive': 1, 'neutral': 0, 'negative': -1})\n",
    "df.review_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "# cria objeto CountVectorizer. O parâmetro ngram_range=(1, 1) significa que o vetorizador \n",
    "# irá considerar apenas unigramas, cada token individual será considerado como uma unidade\n",
    "vect = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# ajusta o vetorizador aos dados de texto fornecido\n",
    "vect.fit(df.Total_Review)\n",
    "\n",
    "with open('count_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vect, f)\n",
    "\n",
    "# transforma os textos em uma representação de matriz de contagem de tokens.\n",
    "text_vect = vect.transform(df.Total_Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide os dados entre treino e teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    text_vect, \n",
    "    df.review_type,\n",
    "    test_size = 0.3, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='newton-cg')\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7641925174545442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_prediction = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide os dados entre treino e teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    text_vect, \n",
    "    df.review_type,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 87.58%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    -1            0            1  accuracy     macro avg  \\\n",
      "precision     0.843244     0.912309     0.878059  0.875791      0.877871   \n",
      "recall        0.882196     0.793840     0.951402  0.875791      0.875812   \n",
      "f1-score      0.862280     0.848961     0.913260  0.875791      0.874834   \n",
      "support    8616.000000  8571.000000  8560.000000  0.875791  25747.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.877810  \n",
      "recall         0.875791  \n",
      "f1-score       0.874796  \n",
      "support    25747.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[7601  460  555]\n",
      " [1191 6804  576]\n",
      " [ 222  194 8144]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 75.89%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    -1            0            1  accuracy    macro avg  \\\n",
      "precision     0.704766     0.738095     0.825093  0.758894     0.755985   \n",
      "recall        0.756155     0.603616     0.916052  0.758894     0.758608   \n",
      "f1-score      0.729557     0.664116     0.868197  0.758894     0.753957   \n",
      "support    2112.000000  2157.000000  2168.000000  0.758894  6437.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.756461  \n",
      "recall         0.758894  \n",
      "f1-score       0.754322  \n",
      "support     6437.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1597  354  161]\n",
      " [ 595 1302  260]\n",
      " [  74  108 1986]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>87.579135</td>\n",
       "      <td>75.889389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Logistic Regression            87.579135           75.889389"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, clf.predict(X_train)) * 100\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# salvar o modelo em um arquivo\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
